{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiate between posts more commonly associated with either the male or female fashion advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize\n",
    "import warnings\n",
    "from psaw import PushshiftAPI\n",
    "\n",
    "# After the imports\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {'confessions' : 'https://www.reddit.com/r/confessions.json', \n",
    "        'relationships' : 'https://www.reddit.com/r/relationships.json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our scraping function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.1 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "api = PushshiftAPI()\n",
    "confessions = pd.DataFrame(list(api.search_submissions(subreddit='confessions',\n",
    "                                         filter=['author','title','subreddit','selftext'],\n",
    "                                         limit=3000)))\n",
    "relationships = pd.DataFrame(list(api.search_submissions(subreddit='relationships',\n",
    "                                         filter=['author','title','subreddit','selftext'],\n",
    "                                         limit=3000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "def reddit_scrapper(key,url,n_iterations=10):\n",
    "    \n",
    "    #load_previous_file\n",
    "    prev_posts = pd.read_csv('./data/' + str(key) + '.csv')\n",
    "    print(\"Number of records loaded : {}\".format(prev_posts.shape[0]))\n",
    "    \n",
    "    posts = []\n",
    "    after = None\n",
    "\n",
    "    for a in range(n_iterations):\n",
    "        if after == None:\n",
    "            current_url = url + '?limit=100'\n",
    "        else:\n",
    "            current_url = url + '?after=' + after + '&limit=100'\n",
    "        print(current_url)\n",
    "        res = requests.get(current_url, headers={'User-agent': 'Falcon 2.0'})\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            print('Status error', res.status_code)\n",
    "            break\n",
    "\n",
    "        current_dict = res.json()\n",
    "        current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "        posts.extend(current_posts)\n",
    "        after = current_dict['data']['after']\n",
    "\n",
    "        # generate a random sleep duration to look more 'natural'\n",
    "        sleep_duration = random.randint(2,6)\n",
    "        \n",
    "        time.sleep(sleep_duration)\n",
    "    \n",
    "    #add_to_existing\n",
    "    posts = pd.DataFrame(posts)\n",
    "    posts_df = posts.append(prev_posts,ignore_index=True)\n",
    "    #remove duplicates\n",
    "    #posts_df.drop_duplicates(inplace=True)\n",
    "    print(\"Number of records stored : {}\".format(posts_df.shape[0]))\n",
    "    posts_df.to_csv('./data/' + str(key) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships = pd.read_csv('./data/relationships.csv')\n",
    "df_confessions = pd.read_csv('./data/confessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `filter_columns` function that filters out the title, self text and subreddit name (our target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(df):\n",
    "    columns_to_retain = ['title','selftext','subreddit','author']\n",
    "    return df[columns_to_retain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean = filter_columns(df_relationships)\n",
    "df_conf_clean = filter_columns(df_confessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        3000\n",
       "selftext     2985\n",
       "subreddit    3000\n",
       "author       3000\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "title        3000\n",
       "selftext     2507\n",
       "subreddit    3000\n",
       "author       3000\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_relationships_clean.count())\n",
    "display(df_conf_clean.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the classes are imbalanced. For our classification dataset, we will aim to have a 1:1 class balance - specifically, we will choose 4200 male and 4200 female fashion posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I (20F) don't know if I want to see my LDR(19M...</td>\n",
       "      <td>I don't know if I want to see my LDR anymore, ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>another4ccount12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does this mean?</td>\n",
       "      <td>Ex got very pissed off and mad when I said tha...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>horse126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friend (22M) is dating my (22M) sister (20F). ...</td>\n",
       "      <td>My friend is dating my sister. At first I was ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>turndownforcat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oof</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>relationships</td>\n",
       "      <td>kelsonyt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I unfairly compare everyone to my ex and I wis...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>relationships</td>\n",
       "      <td>babelfiish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  I (20F) don't know if I want to see my LDR(19M...   \n",
       "1                               What does this mean?   \n",
       "2  Friend (22M) is dating my (22M) sister (20F). ...   \n",
       "3                                                Oof   \n",
       "4  I unfairly compare everyone to my ex and I wis...   \n",
       "\n",
       "                                            selftext      subreddit  \\\n",
       "0  I don't know if I want to see my LDR anymore, ...  relationships   \n",
       "1  Ex got very pissed off and mad when I said tha...  relationships   \n",
       "2  My friend is dating my sister. At first I was ...  relationships   \n",
       "3                                          [removed]  relationships   \n",
       "4                                          [removed]  relationships   \n",
       "\n",
       "                author  \n",
       "0  another4ccount12345  \n",
       "1             horse126  \n",
       "2       turndownforcat  \n",
       "3             kelsonyt  \n",
       "4           babelfiish  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relationships_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I lost my virginity in a 3 way</td>\n",
       "      <td>Im a 19 year old male in a rural town. This ha...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>jdallis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I blame myself</td>\n",
       "      <td>I’m a woman in my early 30s. I’m a lesbian and...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>heynotyouagain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm just realizing that I was assaulted, 7 yea...</td>\n",
       "      <td>I broke up with my ex-boyfriend because he was...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>will0w27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I mistakenly sent an intimate video of my GF a...</td>\n",
       "      <td>This is a long, long post. Full of an excessiv...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>IamAFUkkingIdiot3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m 16, and I’m going to court tomorrow.</td>\n",
       "      <td>Long story short, I got caught by the cops smo...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>holygift462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                     I lost my virginity in a 3 way   \n",
       "1                                     I blame myself   \n",
       "2  I'm just realizing that I was assaulted, 7 yea...   \n",
       "3  I mistakenly sent an intimate video of my GF a...   \n",
       "4           I’m 16, and I’m going to court tomorrow.   \n",
       "\n",
       "                                            selftext    subreddit  \\\n",
       "0  Im a 19 year old male in a rural town. This ha...  confessions   \n",
       "1  I’m a woman in my early 30s. I’m a lesbian and...  confessions   \n",
       "2  I broke up with my ex-boyfriend because he was...  confessions   \n",
       "3  This is a long, long post. Full of an excessiv...  confessions   \n",
       "4  Long story short, I got caught by the cops smo...  confessions   \n",
       "\n",
       "              author  \n",
       "0            jdallis  \n",
       "1     heynotyouagain  \n",
       "2           will0w27  \n",
       "3  IamAFUkkingIdiot3  \n",
       "4        holygift462  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conf_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to this, we may wish to remove posts that have 'Moderator' as an author to train our model on more 'authentic' posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean.loc[:,'author'] = df_relationships_clean.author.map(lambda x : x.lower())\n",
    "df_conf_clean.loc[:,'author'] = df_conf_clean.author.map(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean = df_relationships_clean[~df_relationships_clean.author.str.contains('moderator')]\n",
    "df_conf_clean = df_conf_clean[~df_conf_clean.author.str.contains('moderator')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title         0\n",
       "selftext     15\n",
       "subreddit     0\n",
       "author        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relationships_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "selftext     493\n",
       "subreddit      0\n",
       "author         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conf_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also observe empty selftext in both subreddits. we shall drop rows with empty selftext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean = df_relationships_clean.dropna(axis=0)\n",
    "df_conf_clean = df_conf_clean.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure only posts with selftext more than 10words are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean ['selftext_len'] = df_relationships_clean .selftext.map(lambda x: len(x.split()))\n",
    "df_relationships_clean  = df_relationships_clean [df_relationships_clean .selftext_len > 10]\n",
    "df_conf_clean['selftext_len'] = df_conf_clean.selftext.map(lambda x: len(x.split()))\n",
    "df_conf_clean = df_conf_clean[df_conf_clean.selftext_len > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean.drop_duplicates(inplace=True)\n",
    "df_conf_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           1801\n",
       "selftext        1801\n",
       "subreddit       1801\n",
       "author          1801\n",
       "selftext_len    1801\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "title           2286\n",
       "selftext        2286\n",
       "subreddit       2286\n",
       "author          2286\n",
       "selftext_len    2286\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_relationships_clean.count())\n",
    "display(df_conf_clean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[deleted] Counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    1801\n",
       "Name: title, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    2286\n",
       "Name: title, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[removed] Counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    1801\n",
       "Name: title, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    2286\n",
       "Name: title, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check posts with [deleted] or [removed]\n",
    "print(\"[deleted] Counts:\")\n",
    "display((df_relationships_clean.title == '[deleted]').value_counts())\n",
    "display((df_conf_clean.title == '[deleted]').value_counts())\n",
    "print(\"[removed] Counts:\")\n",
    "display((df_relationships_clean.title == '[removed]').value_counts())\n",
    "display((df_conf_clean.title == '[removed]').value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then randomly select 1800 of each class since quite a significant number were from a moderator-author as well as empty text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_relationships_clean = df_relationships_clean.sample(n=1800,random_state=666)\n",
    "subset_conf_clean = df_conf_clean.sample(n=1800,random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confessions      1800\n",
       "relationships    1800\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both subsets into a DF\n",
    "df = subset_relationships_clean.append(subset_conf_clean,ignore_index=True)\n",
    "df.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I (23F) can't stand my toxic boyfriend (24M) w...</td>\n",
       "      <td>I've been dating my boyfriend for about 3.5 ye...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>faultless_to_a_fault</td>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I [24m] knocked up my girlfriend [22f] of nine...</td>\n",
       "      <td>As the title says, I've been with my girlfrien...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>substantial_program</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My BFF (17/F) keeps lying and breaks my (15/F)...</td>\n",
       "      <td>This is a teens argument so i apologise\\n in a...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>stalinesexslave2</td>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I (M,40) absolutely adore my partner (F,39) bu...</td>\n",
       "      <td>I’m a m of 40 and my partner is 39. We have be...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>iam_mrgee</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My Boyfriend (25m) Called me (28f) Fat Ass.</td>\n",
       "      <td>I dont want to make this a long post so I'm go...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>smellslikecheerios</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  I (23F) can't stand my toxic boyfriend (24M) w...   \n",
       "1  I [24m] knocked up my girlfriend [22f] of nine...   \n",
       "2  My BFF (17/F) keeps lying and breaks my (15/F)...   \n",
       "3  I (M,40) absolutely adore my partner (F,39) bu...   \n",
       "4        My Boyfriend (25m) Called me (28f) Fat Ass.   \n",
       "\n",
       "                                            selftext      subreddit  \\\n",
       "0  I've been dating my boyfriend for about 3.5 ye...  relationships   \n",
       "1  As the title says, I've been with my girlfrien...  relationships   \n",
       "2  This is a teens argument so i apologise\\n in a...  relationships   \n",
       "3  I’m a m of 40 and my partner is 39. We have be...  relationships   \n",
       "4  I dont want to make this a long post so I'm go...  relationships   \n",
       "\n",
       "                 author  selftext_len label  \n",
       "0  faultless_to_a_fault           421     0  \n",
       "1   substantial_program           305     0  \n",
       "2      stalinesexslave2           484     0  \n",
       "3             iam_mrgee           367     0  \n",
       "4    smellslikecheerios           310     0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create target class columns 0 = relationships, 1 = confessions \n",
    "\n",
    "df['label'] = df.subreddit.map({'relationships':'0','confessions':'1'}) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure formatting of text by:\n",
    "- Converting all to lower cases\n",
    "- removing groups of words in parantheses\n",
    "- remove line breaks\n",
    "- removing special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the stop words to a set.\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    #01 convert titles, selftext into lowercase\n",
    "    lower_text = text.lower()\n",
    "    #02 remove brackets and parenthesis from the title and selftext.\n",
    "    no_br_paret_text = re.sub(r'\\(.+?\\)|\\[.+?\\]','',str(lower_text))\n",
    "    #03 remove line breaks\n",
    "    strip_text =  no_br_paret_text.strip()\n",
    "    #04 remove special characters\n",
    "    removed_special = re.sub(r'[^0-9a-zA-Z ]+','',str(strip_text))\n",
    "    #05 remove words less than 3 characters\n",
    "    words_length = re.sub(r'(\\b\\w{1,2}\\b)', '',removed_special) # for words\n",
    "    #05 split into individual words\n",
    "    words = words_length.split()\n",
    "    #06 Remove stop words.\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return (\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cant stand toxic boyfriend game together stop ...</td>\n",
       "      <td>ive dating boyfriend years weve rough patches ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>faultless_to_a_fault</td>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knocked girlfriend nine months terrible idea g...</td>\n",
       "      <td>title says ive girlfriend nine months going re...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>substantial_program</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bff keeps lying breaks heart talkhelp</td>\n",
       "      <td>teens argument apologise advance long boring e...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>stalinesexslave2</td>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absolutely adore partner feel like shes intere...</td>\n",
       "      <td>partner together years two children youngest y...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>iam_mrgee</td>\n",
       "      <td>367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boyfriend called fat ass</td>\n",
       "      <td>dont want make long post going try make easy r...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>smellslikecheerios</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  cant stand toxic boyfriend game together stop ...   \n",
       "1  knocked girlfriend nine months terrible idea g...   \n",
       "2              bff keeps lying breaks heart talkhelp   \n",
       "3  absolutely adore partner feel like shes intere...   \n",
       "4                           boyfriend called fat ass   \n",
       "\n",
       "                                            selftext      subreddit  \\\n",
       "0  ive dating boyfriend years weve rough patches ...  relationships   \n",
       "1  title says ive girlfriend nine months going re...  relationships   \n",
       "2  teens argument apologise advance long boring e...  relationships   \n",
       "3  partner together years two children youngest y...  relationships   \n",
       "4  dont want make long post going try make easy r...  relationships   \n",
       "\n",
       "                 author  selftext_len label  \n",
       "0  faultless_to_a_fault           421     0  \n",
       "1   substantial_program           305     0  \n",
       "2      stalinesexslave2           484     0  \n",
       "3             iam_mrgee           367     0  \n",
       "4    smellslikecheerios           310     0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title','selftext']] = df[['title','selftext']].applymap(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split title and self text into two classifiers where the output of title_classifier and self_text classifier would provide indication of subreddit belonging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titles, and self text into seperate df\n",
    "\n",
    "df_title = df[['title','label']]\n",
    "df_selftext = df[['selftext','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split selftext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df_selftext['selftext']\n",
    "y_text = df_selftext['label']\n",
    "\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_text,y_text,stratify=y_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(tokenizer=LemmaTokenizer())),\n",
    "    ('lr', LogisticRegression(solver='saga',max_iter=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.\n",
      "The scikit-learn version is 0.21.2.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 270 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed: 27.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822962962962963\n"
     ]
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'lr__penalty' : ['elasticnet'],\n",
    "    'lr__C' : np.arange(0.1,1,0.1),\n",
    "    'lr__l1_ratio' : np.arange(0.1,1.1,0.2)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3,verbose=1,n_jobs=-1)\n",
    "gs.fit(X_text_train, y_text_train)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'lr__C': 0.30000000000000004,\n",
       " 'lr__l1_ratio': 0.1,\n",
       " 'lr__penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_.score(X_text_test,y_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
