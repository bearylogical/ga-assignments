{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiate between posts more commonly associated with either the male or female fashion advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize\n",
    "\n",
    "# After the imports\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the URLs\n",
    "\n",
    "class_1 refers to posts in female fashion advice, class_2 refers to posts in male fashion advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {'confessions' : 'https://www.reddit.com/r/confessions.json', \n",
    "        'relationships' : 'https://www.reddit.com/r/relationships.json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our scraping function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "def reddit_scrapper(key,url,n_iterations=10):\n",
    "    \n",
    "    #load_previous_file\n",
    "    prev_posts = pd.read_csv('./data/' + str(key) + '.csv')\n",
    "    print(\"Number of records loaded : {}\".format(prev_posts.shape[0]))\n",
    "    \n",
    "    posts = []\n",
    "    after = None\n",
    "\n",
    "    for a in range(n_iterations):\n",
    "        if after == None:\n",
    "            current_url = url + '?limit=100'\n",
    "        else:\n",
    "            current_url = url + '?after=' + after + '&limit=100'\n",
    "        print(current_url)\n",
    "        res = requests.get(current_url, headers={'User-agent': 'Falcon 2.0'})\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            print('Status error', res.status_code)\n",
    "            break\n",
    "\n",
    "        current_dict = res.json()\n",
    "        current_posts = [p['data'] for p in current_dict['data']['children']]\n",
    "        posts.extend(current_posts)\n",
    "        after = current_dict['data']['after']\n",
    "\n",
    "        # generate a random sleep duration to look more 'natural'\n",
    "        sleep_duration = random.randint(2,6)\n",
    "        \n",
    "        time.sleep(sleep_duration)\n",
    "    \n",
    "    #add_to_existing\n",
    "    posts = pd.DataFrame(posts)\n",
    "    posts_df = posts.append(prev_posts,ignore_index=True)\n",
    "    #remove duplicates\n",
    "    #posts_df.drop_duplicates(inplace=True)\n",
    "    print(\"Number of records stored : {}\".format(posts_df.shape[0]))\n",
    "    posts_df.to_csv('./data/' + str(key) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n",
      "Number of records loaded : 2082\n",
      "https://www.reddit.com/r/confessions.json?limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_bz5m1u&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_bz846y&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_bypsma&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_byhgr9&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_by95fh&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_by40bz&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_bxs4zx&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_bxaifo&limit=100\n",
      "https://www.reddit.com/r/confessions.json?after=t3_bwzxtr&limit=100\n",
      "Number of records stored : 3073\n",
      "Number of records loaded : 1026\n",
      "https://www.reddit.com/r/relationships.json?limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_bzlq65&limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_bzepw8&limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_bz7edn&limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_byxy6w&limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_bz38n0&limit=100\n",
      "https://www.reddit.com/r/relationships.json?limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_bzlq65&limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_bzepw8&limit=100\n",
      "https://www.reddit.com/r/relationships.json?after=t3_bz7edn&limit=100\n",
      "Number of records stored : 1948\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "for subreddit,url in urls.items():\n",
    "    reddit_scrapper(subreddit,url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships = pd.read_csv('./data/relationships.csv')\n",
    "df_confessions = pd.read_csv('./data/confessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `filter_columns` function that filters out the title, self text and subreddit name (our target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(df):\n",
    "    columns_to_retain = ['title','selftext','subreddit','author']\n",
    "    return df[columns_to_retain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean = filter_columns(df_relationships)\n",
    "df_conf_clean = filter_columns(df_confessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        1948\n",
       "selftext     1948\n",
       "subreddit    1948\n",
       "author       1948\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "title        3073\n",
       "selftext     2710\n",
       "subreddit    3073\n",
       "author       3073\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_relationships_clean.count())\n",
    "display(df_conf_clean.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the classes are imbalanced. For our classification dataset, we will aim to have a 1:1 class balance - specifically, we will choose 4200 male and 4200 female fashion posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Should I (28M) tell my good friend (26F) what ...</td>\n",
       "      <td>I've (28M) been very good friends with M (26F)...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>mr_phyr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My (28f) mom (53f) is wanting to move in with ...</td>\n",
       "      <td>My mom text me yesterday and asked me if she c...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>lablife28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My [27F] husband [27M] has betrayed me and lie...</td>\n",
       "      <td>I originally posted some of this on a throwawa...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>glassballerina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A guy that I know turned out to be an ex-boyfr...</td>\n",
       "      <td>She (38F) finally told me (40M) because she th...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>sospecial77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Am I being an ungrateful bitch??</td>\n",
       "      <td>My husband of 28 years keeps insisting on gett...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>tundracatz907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Should I (28M) tell my good friend (26F) what ...   \n",
       "1  My (28f) mom (53f) is wanting to move in with ...   \n",
       "2  My [27F] husband [27M] has betrayed me and lie...   \n",
       "3  A guy that I know turned out to be an ex-boyfr...   \n",
       "4                   Am I being an ungrateful bitch??   \n",
       "\n",
       "                                            selftext      subreddit  \\\n",
       "0  I've (28M) been very good friends with M (26F)...  relationships   \n",
       "1  My mom text me yesterday and asked me if she c...  relationships   \n",
       "2  I originally posted some of this on a throwawa...  relationships   \n",
       "3  She (38F) finally told me (40M) because she th...  relationships   \n",
       "4  My husband of 28 years keeps insisting on gett...  relationships   \n",
       "\n",
       "           author  \n",
       "0         mr_phyr  \n",
       "1       lablife28  \n",
       "2  glassballerina  \n",
       "3     sospecial77  \n",
       "4   tundracatz907  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relationships_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a call center employee in my early 20s, I p...</td>\n",
       "      <td>Context:\\n\\nThis took place in the late 2000s....</td>\n",
       "      <td>confessions</td>\n",
       "      <td>IBoris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whenever someone asks about my parents, I tell...</td>\n",
       "      <td>It happened when I was 15. My father was alway...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>chicagodrama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As I scroll reddit, I save all the things I th...</td>\n",
       "      <td>He thinks that's what I'm looking at when I'm ...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>earthlingmollyrising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am a feminist at work but at home I am a wife</td>\n",
       "      <td>I believe in equal rights for men and women. I...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>AlohaWorld18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I miss the days where there was no social media</td>\n",
       "      <td>I feel like social media is what is wrong with...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>EmperorJoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As a call center employee in my early 20s, I p...   \n",
       "1  Whenever someone asks about my parents, I tell...   \n",
       "2  As I scroll reddit, I save all the things I th...   \n",
       "3    I am a feminist at work but at home I am a wife   \n",
       "4    I miss the days where there was no social media   \n",
       "\n",
       "                                            selftext    subreddit  \\\n",
       "0  Context:\\n\\nThis took place in the late 2000s....  confessions   \n",
       "1  It happened when I was 15. My father was alway...  confessions   \n",
       "2  He thinks that's what I'm looking at when I'm ...  confessions   \n",
       "3  I believe in equal rights for men and women. I...  confessions   \n",
       "4  I feel like social media is what is wrong with...  confessions   \n",
       "\n",
       "                 author  \n",
       "0                IBoris  \n",
       "1          chicagodrama  \n",
       "2  earthlingmollyrising  \n",
       "3          AlohaWorld18  \n",
       "4          EmperorJoker  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conf_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to this, we may wish to remove posts that have 'Moderator' as an author to train our model on more 'authentic' posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syamil/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:635: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "df_relationships_clean.loc[:,'author'] = df_relationships_clean.author.map(lambda x : x.lower())\n",
    "df_conf_clean.loc[:,'author'] = df_conf_clean.author.map(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean = df_relationships_clean[~df_relationships_clean.author.str.contains('moderator')]\n",
    "df_conf_clean = df_conf_clean[~df_conf_clean.author.str.contains('moderator')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "selftext     0\n",
       "subreddit    0\n",
       "author       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relationships_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "selftext     363\n",
       "subreddit      0\n",
       "author         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conf_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also observe empty selftext in both subreddits. we shall drop rows with empty selftext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean = df_relationships_clean.dropna(axis=0)\n",
    "df_conf_clean = df_conf_clean.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure only posts with selftext more than 10 are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean ['selftext_len'] = df_relationships_clean .selftext.map(lambda x: len(x.split()))\n",
    "df_relationships_clean  = df_relationships_clean [df_relationships_clean .selftext_len > 10]\n",
    "df_conf_clean['selftext_len'] = df_conf_clean.selftext.map(lambda x: len(x.split()))\n",
    "df_conf_clean = df_conf_clean[df_conf_clean.selftext_len > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relationships_clean.drop_duplicates(inplace=True)\n",
    "df_conf_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           595\n",
       "selftext        595\n",
       "subreddit       595\n",
       "author          595\n",
       "selftext_len    595\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "title           837\n",
       "selftext        837\n",
       "subreddit       837\n",
       "author          837\n",
       "selftext_len    837\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_relationships_clean.count())\n",
    "display(df_conf_clean.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then randomly select 3000 of each class since quite a significant number were from a moderator-author as well as empty text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_relationships_clean = df_relationships_clean.sample(n=500,random_state=666)\n",
    "subset_conf_clean = df_conf_clean.sample(n=500,random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confessions      500\n",
       "relationships    500\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both subsets into a DF\n",
    "df = subset_relationships_clean.append(subset_conf_clean,ignore_index=True)\n",
    "df.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A HS friend [23F] I haven’t spoken to in a yea...</td>\n",
       "      <td>I had a friend in high school, T, that I got c...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>cthegoldfish</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Im (26M) seeing a (23F) that draws block eyebr...</td>\n",
       "      <td>I (26M) and seeing A (23F) Taiwanese girl who ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>kynewt</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Me (24F) and my boyfriend (24M) haven't spoken...</td>\n",
       "      <td>Long story short - we had agreed to go to a fe...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>bigeasterbunny</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Should I request my(21F) Fiance(25M) track dow...</td>\n",
       "      <td>So my fiance and I have been together for 1.5 ...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>hamburgleryourgirl</td>\n",
       "      <td>589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My [28m] GF [29m] of about 4 months declined t...</td>\n",
       "      <td>So I need to start by saying I realize how stu...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>tsaaron</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A HS friend [23F] I haven’t spoken to in a yea...   \n",
       "1  Im (26M) seeing a (23F) that draws block eyebr...   \n",
       "2  Me (24F) and my boyfriend (24M) haven't spoken...   \n",
       "3  Should I request my(21F) Fiance(25M) track dow...   \n",
       "4  My [28m] GF [29m] of about 4 months declined t...   \n",
       "\n",
       "                                            selftext      subreddit  \\\n",
       "0  I had a friend in high school, T, that I got c...  relationships   \n",
       "1  I (26M) and seeing A (23F) Taiwanese girl who ...  relationships   \n",
       "2  Long story short - we had agreed to go to a fe...  relationships   \n",
       "3  So my fiance and I have been together for 1.5 ...  relationships   \n",
       "4  So I need to start by saying I realize how stu...  relationships   \n",
       "\n",
       "               author  selftext_len label  \n",
       "0        cthegoldfish           740     0  \n",
       "1              kynewt           204     0  \n",
       "2      bigeasterbunny           281     0  \n",
       "3  hamburgleryourgirl           589     0  \n",
       "4             tsaaron           345     0  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create target class columns 0 = relationships, 1 = confessions \n",
    "\n",
    "df['label'] = df.subreddit.map({'relationships':'0','confessions':'1'}) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure formatting of text by:\n",
    "- Converting all to lower cases\n",
    "- removing groups of words in parantheses\n",
    "- remove line breaks\n",
    "- removing special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the stop words to a set.\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    #01 convert titles, selftext into lowercase\n",
    "    lower_text = text.lower()\n",
    "    #02 remove brackets and parenthesis from the title and selftext.\n",
    "    no_br_paret_text = re.sub(r'\\(.+?\\)|\\[.+?\\]','',str(lower_text))\n",
    "    #03 remove line breaks\n",
    "    strip_text =  no_br_paret_text.strip()\n",
    "    #04 remove special characters\n",
    "    removed_special = re.sub(r'[^0-9a-zA-Z ]+','',str(strip_text))\n",
    "    #05 remove words less than 3 characters\n",
    "    words_length = re.sub(r'(\\b\\w{1,2}\\b)', '',removed_special) # for words\n",
    "    #05 split into individual words\n",
    "    words = words_length.split()\n",
    "    #06 Remove stop words.\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    return (\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>girl fell love didnt</td>\n",
       "      <td>far friends told crazy loved much couldnt shar...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>ali4069</td>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>wish morrissey would run president</td>\n",
       "      <td>weird obsession want morrissey run president d...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>theriderreturns</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>want join ram ranch</td>\n",
       "      <td>idea ram ranch really arouses anybody advice o...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>theriderreturns</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>dont think really believe anything anymore</td>\n",
       "      <td>feel like dont strong beliefs religion really ...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>mrlurkety</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>think parents gas lighted ever since young</td>\n",
       "      <td>first events really havent happened long ago o...</td>\n",
       "      <td>confessions</td>\n",
       "      <td>sofw2424</td>\n",
       "      <td>1066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "995                        girl fell love didnt   \n",
       "996          wish morrissey would run president   \n",
       "997                         want join ram ranch   \n",
       "998  dont think really believe anything anymore   \n",
       "999  think parents gas lighted ever since young   \n",
       "\n",
       "                                              selftext    subreddit  \\\n",
       "995  far friends told crazy loved much couldnt shar...  confessions   \n",
       "996  weird obsession want morrissey run president d...  confessions   \n",
       "997  idea ram ranch really arouses anybody advice o...  confessions   \n",
       "998  feel like dont strong beliefs religion really ...  confessions   \n",
       "999  first events really havent happened long ago o...  confessions   \n",
       "\n",
       "              author  selftext_len label  \n",
       "995          ali4069           323     1  \n",
       "996  theriderreturns           127     1  \n",
       "997  theriderreturns            21     1  \n",
       "998        mrlurkety            89     1  \n",
       "999         sofw2424          1066     1  "
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['title','selftext']] = df[['title','selftext']].applymap(clean_text)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split title and self text into two classifiers where the output of title_classifier and self_text classifier would provide indication of subreddit belonging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split titles, and self text into seperate df\n",
    "\n",
    "df_title = df[['title','label']]\n",
    "df_selftext = df[['selftext','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split selftext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = df_selftext['selftext']\n",
    "y_text = df_selftext['label']\n",
    "\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_text,y_text,stratify=y_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(tokenizer=LemmaTokenizer())),\n",
    "    ('lr', LogisticRegression(solver='saga',max_iter=300))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2940 candidates, totalling 8820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed: 51.7min\n",
      "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed: 71.6min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-417-e54596ba122c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_text_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_text_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'lr__penalty' : ['elasticnet'],\n",
    "    'lr__C' : np.arange(0.1,5,0.1),\n",
    "    'lr__l1_ratio' : np.arange(0.1,1.1,0.1)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3,verbose=1,n_jobs=2)\n",
    "gs.fit(X_text_train, y_text_train)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
